# Charity Data Engineering Project 

- [x] Create a Python script to generate CSV files with Faker.
- [x] Ensure the script appends new data to existing CSV files.
- [x] Save the data to data file 
- [x] Create a Resource Group in Azure (`charity_data_project_rg`).
- [x] Create an Azure Storage Account (`charitydatastorage`).
- [x] Add containers for `raw`, `curated`, and `presentation` layers.
- [x] Upload generated data to the `raw` container.
- [ ] Set up Azure Data Factory for ETL pipelines.
- [ ] Configure multi-hop data processing pipelines.
- [ ] Set up Azure Synapse Analytics or Azure SQL for final data storage.
- [ ] Create Power BI reports for data visualization.
